{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00e4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb05650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def avg_length_string_variables(source_code):\n",
    "    string_assignments = re.findall(r'=\\s*\"[^\"]*\"', source_code)\n",
    "    if not string_assignments:\n",
    "        return 0\n",
    "    lengths = [len(s) - 3 for s in string_assignments] \n",
    "    return sum(lengths) / len(lengths) if lengths else 0\n",
    "\n",
    "def check_for_real_words(source_code):\n",
    "    return 1000 if len(source_code) == 1 else 0\n",
    "\n",
    "def count_integer_variables(source_code):\n",
    "    int_vars = re.findall(r'\\bDim\\s+\\w+\\s+As\\s+Integer\\b', source_code)\n",
    "    return len(int_vars) / len(source_code.split())\n",
    "\n",
    "def count_string_variables(source_code):\n",
    "    string_vars = re.findall(r'\\bDim\\s+\\w+\\s+As\\s+String\\b', source_code)\n",
    "    return len(string_vars) / len(source_code.split()) \n",
    "\n",
    "def has_macro_keywords(source_code):\n",
    "    keywords = ['autoopen', 'autoclose', 'documentopen', 'documentclose', '13', 'cells', 'value']\n",
    "    return any(keyword in source_code.lower() for keyword in keywords)\n",
    "\n",
    "\n",
    "def max_consecutive_math_operations(source_code):\n",
    "    operations_pattern = re.compile(r'[\\+\\-\\*/]{2,}') \n",
    "    matches = operations_pattern.findall(source_code)\n",
    "    if matches:\n",
    "        return max(len(match) for match in matches)\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251acfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vba_code', 'avg_var_assignment_length', 'count_int_vars',\n",
      "       'count_string_vars', 'macro_keywords', 'max_consecutive_math_ops',\n",
      "       'one_char'],\n",
      "      dtype='object')\n",
      "Index(['vba_code', 'avg_var_assignment_length', 'count_int_vars',\n",
      "       'count_string_vars', 'macro_keywords', 'max_consecutive_math_ops',\n",
      "       'one_char'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def extract_features(source_code):\n",
    "    features = {\n",
    "        'avg_var_assignment_length': avg_length_string_variables(source_code),\n",
    "        'count_int_vars': count_integer_variables(source_code),\n",
    "        'count_string_vars': count_string_variables(source_code),\n",
    "        'macro_keywords': int(has_macro_keywords(source_code)), \n",
    "        'max_consecutive_math_ops': max_consecutive_math_operations(source_code),\n",
    "        'one_char': check_for_real_words(source_code),\n",
    "    }\n",
    "    return features\n",
    "\n",
    "\n",
    "validation_file_path = \"validation_dataset.csv\"  \n",
    "df_validation = pd.read_csv(validation_file_path, encoding='utf-16-le') \n",
    "\n",
    "df_validation['label']=df_validation['label'].map({'white':1,'mal':0})\n",
    "x_validation = df_validation[\"vba_code\"]\n",
    "y_validation = df_validation[\"label\"]\n",
    "\n",
    "test_file_path = 'test_dataset_without_labels.csv' \n",
    "df_test = pd.read_csv(test_file_path, encoding='utf-16-le')\n",
    "x_test = df_test['vba_code']\n",
    "\n",
    "# Correctly convert Series to DataFrame if necessary and ensure structure\n",
    "x_validation_df = pd.DataFrame(x_validation, columns=['vba_code']) if isinstance(x_validation, pd.Series) else x_validation\n",
    "x_test_df = pd.DataFrame(x_test, columns=['vba_code']) if isinstance(x_test, pd.Series) else x_test\n",
    "\n",
    "# Apply feature extraction\n",
    "new_features_val = x_validation_df['vba_code'].apply(extract_features)\n",
    "new_features_test = x_test_df['vba_code'].apply(extract_features)\n",
    "\n",
    "# Convert the result into DataFrames\n",
    "new_features_val_df = pd.DataFrame(new_features_val.tolist())\n",
    "new_features_test_df = pd.DataFrame(new_features_test.tolist())\n",
    "\n",
    "# Concatenate the new features with the original DataFrames\n",
    "x_validation_combined = pd.concat([x_validation_df.reset_index(drop=True), new_features_val_df], axis=1)\n",
    "x_test_combined = pd.concat([x_test_df.reset_index(drop=True), new_features_test_df], axis=1)\n",
    "\n",
    "print(x_validation_combined.columns)\n",
    "print(x_test_combined.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e0e2c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.993 / Recall: 0.998 / Accuracy: 0.995\n",
      "{'preprocessor': ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                 ['avg_var_assignment_length', 'count_int_vars',\n",
      "                                  'count_string_vars', 'macro_keywords',\n",
      "                                  'max_consecutive_math_ops', 'one_char']),\n",
      "                                ('text', TfidfVectorizer(), 'vba_code')]), 'feature_selection': SelectFromModel(estimator=RandomForestClassifier(max_depth=10, random_state=42)), 'classification': RandomForestClassifier(random_state=42)}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      5320\n",
      "           1       0.99      1.00      1.00      5309\n",
      "\n",
      "    accuracy                           1.00     10629\n",
      "   macro avg       1.00      1.00      1.00     10629\n",
      "weighted avg       1.00      1.00      1.00     10629\n",
      "\n",
      "[[5285   35]\n",
      " [  13 5296]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "with open('train.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "try:\n",
    "    validation_predictions = loaded_model.predict(x_validation_combined)\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)\n",
    "except KeyError as e:\n",
    "    print(\"KeyError:\", e)\n",
    "\n",
    "precision = precision_score(y_validation, validation_predictions )\n",
    "recall = recall_score(y_validation, validation_predictions )\n",
    "\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "      round(precision, 3), round(recall, 3), round((validation_predictions ==y_validation).sum()/len(validation_predictions ), 3)))\n",
    "\n",
    "\n",
    "print(loaded_model.named_steps) \n",
    "print(classification_report(y_validation, validation_predictions))\n",
    "print(confusion_matrix(y_validation, validation_predictions, labels=np.unique(y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f65ae2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_prediction = loaded_model.predict(x_test_combined)\n",
    "\n",
    "\n",
    "dictionary = {\n",
    "    1: 'white',\n",
    "    0: 'mal'\n",
    "}\n",
    "\n",
    "predictions = [dictionary[i] for i in test_prediction]\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions, columns=['prediction'])\n",
    "\n",
    "predictions_df.to_csv('test_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80abebe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
