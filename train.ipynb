{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b297b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de22065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def avg_length_string_variables(source_code):\n",
    "    string_assignments = re.findall(r'=\\s*\"[^\"]*\"', source_code)\n",
    "    if not string_assignments:\n",
    "        return 0\n",
    "    lengths = [len(s) - 3 for s in string_assignments] \n",
    "    return sum(lengths) / len(lengths) if lengths else 0\n",
    "\n",
    "def check_for_real_words(source_code):\n",
    "    return 1000 if len(source_code) == 1 else 0\n",
    "\n",
    "def count_integer_variables(source_code):\n",
    "    int_vars = re.findall(r'\\bDim\\s+\\w+\\s+As\\s+Integer\\b', source_code)\n",
    "    return len(int_vars) / len(source_code.split())\n",
    "\n",
    "def count_string_variables(source_code):\n",
    "    string_vars = re.findall(r'\\bDim\\s+\\w+\\s+As\\s+String\\b', source_code)\n",
    "    return len(string_vars) / len(source_code.split()) \n",
    "\n",
    "def has_macro_keywords(source_code):\n",
    "    keywords = ['autoopen', 'autoclose', 'documentopen', 'documentclose', '13', 'cells', 'value']\n",
    "    return any(keyword in source_code.lower() for keyword in keywords)\n",
    "\n",
    "\n",
    "def max_consecutive_math_operations(source_code):\n",
    "    operations_pattern = re.compile(r'[\\+\\-\\*/]{2,}') \n",
    "    matches = operations_pattern.findall(source_code)\n",
    "    if matches:\n",
    "        return max(len(match) for match in matches)\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88701b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(31888, 7)\n",
      "Index(['vba_code', 'avg_var_assignment_length', 'count_int_vars',\n",
      "       'count_string_vars', 'macro_keywords', 'max_consecutive_math_ops',\n",
      "       'one_char'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def extract_features(source_code):\n",
    "    features = {\n",
    "        'avg_var_assignment_length': avg_length_string_variables(source_code),\n",
    "        'count_int_vars': count_integer_variables(source_code),\n",
    "        'count_string_vars': count_string_variables(source_code),\n",
    "        'macro_keywords': int(has_macro_keywords(source_code)), \n",
    "        'max_consecutive_math_ops': max_consecutive_math_operations(source_code),\n",
    "        'one_char': check_for_real_words(source_code),\n",
    "    }\n",
    "    return features\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "train_file_path = \"train_dataset.csv\"\n",
    "df = pd.read_csv(train_file_path, encoding='utf-16-le')\n",
    "\n",
    "df['label']=df['label'].map({'white':1,'mal':0})\n",
    "\n",
    "# Separate the features and the target variable\n",
    "x_train = df['vba_code']  \n",
    "y_train = df['label']\n",
    "\n",
    "# Convert x_train to a DataFrame\n",
    "x_train_df = x_train.to_frame()\n",
    "\n",
    "# Apply the feature extraction function to each row of x_train DataFrame\n",
    "new_features = x_train_df.apply(lambda row: extract_features(row['vba_code']), axis=1)\n",
    "\n",
    "# Convert the result into a DataFrame\n",
    "new_features_df = pd.DataFrame(new_features.tolist())\n",
    "\n",
    "# Combine original df with new features\n",
    "x_train_combined = pd.concat([df, new_features_df], axis=1)\n",
    "\n",
    "\n",
    "x_train_ready = x_train_combined.drop(['label' ], axis=1)\n",
    "\n",
    "print(type(x_train_ready))\n",
    "print(x_train_ready.shape)\n",
    "print(x_train_ready.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0221bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['avg_var_assignment_length', 'count_int_vars', 'count_string_vars', 'macro_keywords', 'max_consecutive_math_ops','one_char']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('text', TfidfVectorizer(), 'vba_code'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectFromModel(RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42))),\n",
    "   ('classification', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cf4fcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('num', StandardScaler(), ['avg_var_assignment_length', 'count_int_vars', 'count_string_vars', 'macro_keywords', 'max_consecutive_math_ops', 'one_char']), ('text', TfidfVectorizer(), 'vba_code')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    pipeline.fit(x_train_ready, y_train)\n",
    "\n",
    "    with open('train.pkl', 'wb') as file:\n",
    "        pickle.dump(pipeline, file)\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(\"ValueError:\", e)\n",
    "except KeyError as e:\n",
    "    print(\"KeyError:\", e)\n",
    "\n",
    "print(pipeline.named_steps['preprocessor'].transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde6714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
